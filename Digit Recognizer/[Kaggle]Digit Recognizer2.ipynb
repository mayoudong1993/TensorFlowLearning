{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayoudong/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('~/Downloads/train.csv')\n",
    "X_test = pd.read_csv('~/Downloads/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
      "       'pixel6', 'pixel7', 'pixel8',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=785)\n",
      "Index(['label', 'pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5',\n",
      "       'pixel6', 'pixel7', 'pixel8',\n",
      "       ...\n",
      "       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n",
      "       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n",
      "      dtype='object', length=785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(train.columns)\n",
    "print(train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['label'], axis = 1)\n",
    "Y_train = train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n",
      "(42000, 784)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[1 0 1 ... 7 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_train.values)\n",
    "print(Y_train.values)\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader():\n",
    "    \n",
    "    def __init__(self, length, width, depth, nb_classes):\n",
    "        self.i = 0\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.nb_classes = nb_classes\n",
    "        \n",
    "        self.training_images = None\n",
    "        self.training_labels = None\n",
    "        \n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "        \n",
    "    #train_data (data_size, picturepixels)\n",
    "    def set_up_images(self, train_data):\n",
    "        self.training_images = train_data.values.reshape(-1, self.length, self.width, self.depth)\n",
    "        self.training_labels = np.eye(self.nb_classes)[Y_train.values]\n",
    "        \n",
    "        print(self.training_images.shape)\n",
    "        print(self.training_labels.shape)\n",
    "        print(\"Setting Up Training Images and Labels\")\n",
    "    \n",
    "    def call_setup(self, all_train_batches):\n",
    "        self.set_up_images(all_train_batches)\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        x = self.training_images[self.i:self.i+batch_size]\n",
    "        y = self.training_labels[self.i:self.i+batch_size]\n",
    "        self.i = (self.i + batch_size) % len(self.training_images)\n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n",
      "(42000, 10)\n",
      "Setting Up Training Images and Labels\n"
     ]
    }
   ],
   "source": [
    "DR = DataReader(28, 28, 1, 10)\n",
    "DR.call_setup(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the ModelÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, train_images, train_labels):\n",
    "        self.train = None\n",
    "        self.y_pred = None\n",
    "        self.train_images = train_images\n",
    "        self.train_labels = train_labels\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.hold_prob = None\n",
    "    \n",
    "    def create_placeholder(self):\n",
    "        inputshape = [None, self.train_images.shape[1], self.train_images.shape[2], self.train_images.shape[3]]\n",
    "        labelshape = [None, self.train_labels.shape[1]]\n",
    "        self.x = tf.placeholder(tf.float32,shape=inputshape)\n",
    "        self.y = tf.placeholder(tf.float32,shape=labelshape)\n",
    "        self.hold_prob = tf.placeholder(tf.float32)\n",
    "        #return x, y, hold_prob\n",
    "    \n",
    "    def init_weights(self, shape):\n",
    "        init_random_dist = tf.truncated_normal(shape, stddev=0.1)\n",
    "        return tf.Variable(init_random_dist)\n",
    "\n",
    "    def init_bias(self, shape):\n",
    "        init_bias_vals = tf.constant(0.1, shape=shape)\n",
    "        return tf.Variable(init_bias_vals)\n",
    "    \n",
    "    def conv2d(self, x, W):\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    def max_pool_2by2(self, x):\n",
    "        return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                              strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    def convolutional_layer(self, input_x, shape):\n",
    "        W = self.init_weights(shape)\n",
    "        b = self.init_bias([shape[3]])\n",
    "        return tf.nn.relu(self.conv2d(input_x, W) + b)\n",
    "\n",
    "    def normal_full_layer(self, input_layer, size):\n",
    "        input_size = int(input_layer.get_shape()[1])\n",
    "        W = self.init_weights([input_size, size])\n",
    "        b = self.init_bias([size])\n",
    "        return tf.matmul(input_layer, W) + b\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.create_placeholder()\n",
    "        convo_1 = self.convolutional_layer(self.x,shape=[4,4,1,32])\n",
    "        convo_1_pooling = self.max_pool_2by2(convo_1)\n",
    "        convo_2 = self.convolutional_layer(convo_1_pooling,shape=[4,4,32,64])\n",
    "        convo_2_pooling = self.max_pool_2by2(convo_2)\n",
    "        convo_2_flat = tf.reshape(convo_2_pooling,[-1, 7 * 7 * 64])\n",
    "        full_layer_one = tf.nn.relu(self.normal_full_layer(convo_2_flat,1024))\n",
    "        full_one_dropout = y_pred(full_layer_one,keep_prob=self.hold_prob)\n",
    "        self.y_pred = self.normal_full_layer(full_one_dropout,10)\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y ,logits=self.y_pred))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        self.train = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mymodel = Model(DR.training_images, DR.training_labels)\n",
    "Mymodel.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "(28000, 784)\n",
      "<__main__.Model object at 0x127e65048>\n",
      "[[ 22.993572   -12.133835   121.311295   ... -12.593657     3.964936\n",
      "  -19.702015  ]\n",
      " [ 72.215034   -59.86487      6.6718297  ...  -2.9259427  -11.377503\n",
      "    3.3662803 ]\n",
      " [-24.7682       1.915975     7.820847   ...   3.3839717    9.317007\n",
      "   51.59917   ]\n",
      " ...\n",
      " [-17.03285    -17.386726   -13.484908   ...   2.049852    11.149509\n",
      "   12.540917  ]\n",
      " [  1.1276504  -38.89111    -37.12119    ...  25.419815    17.310036\n",
      "   71.84401   ]\n",
      " [  0.47312123  -2.7598608   93.43433    ... -18.252129    27.623747\n",
      "   -5.6012673 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(1000):\n",
    "        batch = DR.next_batch(100)\n",
    "        sess.run(Mymodel.train, feed_dict={Mymodel.x: batch[0], Mymodel.y: batch[1], Mymodel.hold_prob: 0.5})\n",
    "        if (i % 10 == 0):\n",
    "            print(i)\n",
    "    print(X_test.shape)\n",
    "    test_x = X_test.values.reshape(28000, 28, 28, 1)\n",
    "    print(Mymodel)\n",
    "    Mymodel.y_pred = sess.run(Mymodel.y_pred, feed_dict={Mymodel.x: test_x, Mymodel.hold_prob: 1})\n",
    "    print(Mymodel.y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "[[ 22.993572   -12.133835   121.311295   ... -12.593657     3.964936\n",
      "  -19.702015  ]\n",
      " [ 72.215034   -59.86487      6.6718297  ...  -2.9259427  -11.377503\n",
      "    3.3662803 ]\n",
      " [-24.7682       1.915975     7.820847   ...   3.3839717    9.317007\n",
      "   51.59917   ]\n",
      " ...\n",
      " [-17.03285    -17.386726   -13.484908   ...   2.049852    11.149509\n",
      "   12.540917  ]\n",
      " [  1.1276504  -38.89111    -37.12119    ...  25.419815    17.310036\n",
      "   71.84401   ]\n",
      " [  0.47312123  -2.7598608   93.43433    ... -18.252129    27.623747\n",
      "   -5.6012673 ]]\n",
      "(28000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Mymodel.y_pred)\n",
    "print(Mymodel.y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 ... 3 9 2]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result = sess.run(tf.argmax(Mymodel.y_pred, 1))\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = pd.Series(result, name = \"Label\")\n",
    "submission = pd.concat([pd.Series(range(1, 28001), name = \"ImageId\"), res], axis = 1)\n",
    "submission.to_csv(\"Submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12934ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(DR.training_images[7].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
